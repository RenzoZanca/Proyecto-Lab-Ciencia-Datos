# ğŸ¥¤ SodAI - Sistema de RecomendaciÃ³n de Productos

Sistema MLOps completo para generar recomendaciones de productos usando Airflow, FastAPI y Gradio.

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos
- Docker Desktop instalado y ejecutÃ¡ndose
- Al menos 4GB de RAM disponible para Docker

### Lanzar el Sistema Completo

```bash
./launch_all.sh
```

Este script automÃ¡ticamente:
- âœ… Crea la red Docker necesaria
- âœ… Inicia Airflow (pipeline ML)
- âœ… Inicia el Backend (API)
- âœ… Inicia el Frontend (interfaz web)
- âœ… Activa el DAG automÃ¡ticamente

### Acceder al Sistema

Una vez iniciado, puedes acceder a:

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Frontend** | http://localhost:7860 | Interfaz principal para subir archivos |
| **Backend API** | http://localhost:8000 | API REST para gestiÃ³n de trabajos |
| **Airflow** | http://localhost:8080 | Dashboard del pipeline ML |

## ğŸ“ Usar el Sistema

1. **Accede al frontend**: http://localhost:7860
2. **Sube los archivos parquet**:
   - `clientes.parquet`
   - `productos.parquet` 
   - `transacciones.parquet`
3. **Haz clic en "Subir Archivos e Iniciar Procesamiento"**
4. **Observa el progreso** en tiempo real
5. **Descarga o visualiza los resultados** cuando termine

## ğŸ”§ Herramientas de DiagnÃ³stico

### Si tienes problemas de conectividad:

```bash
./fix_connectivity.sh
```

### Para diagnÃ³stico detallado:

```bash
./diagnose_system.sh
```

### Ver guÃ­a completa de soluciÃ³n de problemas:

```bash
cat SOLUCION_ERRORES_CONECTIVIDAD.md
```

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚    Airflow      â”‚
â”‚   (Gradio)      â”‚â”€â”€â”€â”€â”‚   (FastAPI)     â”‚â”€â”€â”€â”€â”‚   (Pipeline)    â”‚
â”‚   Port: 7860    â”‚    â”‚   Port: 8000    â”‚    â”‚   Port: 8080    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Shared Volume   â”‚
                       â”‚ (Data & Models) â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **Frontend (Gradio)**: Interfaz web para cargar archivos y visualizar resultados
2. **Backend (FastAPI)**: API REST que gestiona trabajos y se comunica con Airflow
3. **Airflow**: Ejecuta el pipeline ML con todas las tareas de procesamiento
4. **Volumen compartido**: Almacena datos y modelos entre servicios

## ğŸ“Š Pipeline ML

El sistema ejecuta automÃ¡ticamente:

1. **ğŸ” VerificaciÃ³n de datos** - Valida formato parquet
2. **ğŸ“Š ObtenciÃ³n de datos** - Carga los archivos
3. **âš™ï¸ Procesamiento** - Limpieza y preparaciÃ³n
4. **ğŸ¯ DivisiÃ³n holdout** - Separa datos de entrenamiento/prueba
5. **ğŸ”§ IngenierÃ­a de caracterÃ­sticas** - Crea features para ML
6. **ğŸ“ˆ DetecciÃ³n de drift** - Analiza cambios en los datos
7. **ğŸ¤” DecisiÃ³n de reentrenamiento** - Decide si entrenar modelo nuevo
8. **ğŸš€ OptimizaciÃ³n de hiperparÃ¡metros** - Busca mejores parÃ¡metros
9. **ğŸ¯ Entrenamiento del modelo** - Entrena modelo final
10. **ğŸ“ˆ EvaluaciÃ³n** - Valida performance
11. **ğŸ’¾ ExportaciÃ³n** - Guarda modelo entrenado
12. **ğŸ¯ GeneraciÃ³n de predicciones** - Crea recomendaciones
13. **ğŸ›ï¸ ObtenciÃ³n de productos** - Prepara resultados finales

## ğŸ“ˆ CaracterÃ­sticas

- âœ… **Interfaz amigable** con Gradio
- âœ… **Progreso en tiempo real** con estimaciones de tiempo
- âœ… **ValidaciÃ³n automÃ¡tica** de archivos parquet
- âœ… **OptimizaciÃ³n de memoria** para evitar crashes
- âœ… **Logging detallado** de cada paso
- âœ… **VisualizaciÃ³n de resultados** directa en la interfaz
- âœ… **Descarga de resultados** en CSV
- âœ… **EstadÃ­sticas automÃ¡ticas** de las predicciones

## ğŸ› ï¸ Comandos Ãštiles

### GestiÃ³n del Sistema

```bash
# Inicio completo
./launch_all.sh

# DiagnÃ³stico
./diagnose_system.sh

# ReparaciÃ³n rÃ¡pida
./fix_connectivity.sh

# Parar todos los servicios
docker-compose -f app/docker-compose.yml down
docker-compose -f airflow/docker-compose.yml down
```

### Monitoreo

```bash
# Ver contenedores ejecutÃ¡ndose
docker ps

# Ver logs de servicios
docker-compose -f airflow/docker-compose.yml logs -f
docker-compose -f app/docker-compose.yml logs -f

# Estado del sistema
curl http://localhost:8000/system/status
```

### Limpieza

```bash
# Limpieza completa
docker-compose -f app/docker-compose.yml down
docker-compose -f airflow/docker-compose.yml down
docker network rm sodai-network
docker volume rm sodai-shared-data
```

## ğŸš¨ SoluciÃ³n de Problemas

### Errores Comunes

| Error | Causa | SoluciÃ³n |
|-------|-------|----------|
| `NameResolutionError: Failed to resolve 'sodai-airflow'` | Contenedores no en misma red | `./fix_connectivity.sh` |
| `Could not check DAG status: 401` | Airflow inicializando | Esperar 2-3 minutos |
| `No se pudo activar el DAG` | Backend no conecta a Airflow | `./fix_connectivity.sh` |
| `Error de memoria` en optimizaciÃ³n | Pocos recursos | Aumentar RAM de Docker |

### Verificaciones RÃ¡pidas

```bash
# Â¿EstÃ¡n todos los servicios ejecutÃ¡ndose?
docker ps | grep sodai

# Â¿Pueden los servicios comunicarse?
docker exec sodai-backend curl http://sodai-airflow:8080/health

# Â¿EstÃ¡n en la misma red?
docker network inspect sodai-network
```

## ğŸ“š DocumentaciÃ³n Adicional

- [GuÃ­a de SoluciÃ³n de Errores](SOLUCION_ERRORES_CONECTIVIDAD.md)
- [DocumentaciÃ³n TÃ©cnica](documentation.md)
- [Conclusiones del Proyecto](conclusiones.md)

## ğŸ”§ Desarrollo

### Estructura del Proyecto

```
Proyecto-Lab-Ciencia-Datos/
â”œâ”€â”€ airflow/                # Pipeline ML
â”‚   â”œâ”€â”€ dag.py             # DefiniciÃ³n del DAG
â”‚   â”œâ”€â”€ data_functions.py  # Funciones de datos
â”‚   â”œâ”€â”€ train_functions.py # Funciones de entrenamiento
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ app/                   # AplicaciÃ³n web
â”‚   â”œâ”€â”€ backend/           # API FastAPI
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ frontend/          # Interfaz Gradio
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ launch_all.sh          # Script de inicio
â”œâ”€â”€ diagnose_system.sh     # Herramienta de diagnÃ³stico
â””â”€â”€ fix_connectivity.sh    # SoluciÃ³n rÃ¡pida
```

### APIs Disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/upload_and_start` | POST | Sube archivos e inicia procesamiento |
| `/job/{job_id}/status` | GET | Estado de un trabajo |
| `/job/{job_id}/logs` | GET | Logs de un trabajo |
| `/job/{job_id}/download` | GET | Descarga resultados |
| `/dag/status` | GET | Estado del DAG |
| `/dag/activate` | POST | Activa el DAG |
| `/system/status` | GET | Estado del sistema |

## ğŸ¯ Resultados

El sistema genera:

- **Archivo CSV** con recomendaciones de productos
- **EstadÃ­sticas detalladas** en la interfaz web:
  - Total de recomendaciones
  - Clientes Ãºnicos con recomendaciones
  - Productos Ãºnicos recomendados
  - EstadÃ­sticas de probabilidad
  - Top 5 clientes y productos

## ğŸ“Š Performance

- **OptimizaciÃ³n de memoria** para datasets grandes
- **ParalelizaciÃ³n** de tareas ML
- **LÃ­mites de memoria** configurables
- **Logging eficiente** sin sobrecargar el sistema

## ğŸ¤ Contribuir

1. Haz fork del proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.